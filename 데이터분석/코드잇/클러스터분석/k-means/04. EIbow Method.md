
## k 선정이 중요한 이유
k-means의 성능은 클러스터의 개수에 따라 달라진다.
예를 들어보면 ![8-1](https://bakey-api.codeit.kr/api/files/resource?root=static&seqId=5810&directory=8-1.png&name=8-1.png)
k-means로 클러스터링을 할때 클러스터의 개수를 몇개로 하는게 적잘한가
만약 k가 2일 경우는 거리가 먼 데이터가 같은 클러스터로 묶이게 된다. 그리고 , 가까우에 있는 데이터는 다른 클러스터로 구분되어있는다. 잘된클러스터링은 아니다.![8-2](https://bakey-api.codeit.kr/api/files/resource?root=static&seqId=5810&directory=8-2.png&name=8-2.png)

반면에 클러스터의 개수가 너무 많으면 클러스터링 의미가 사라진다.
비슷한 데이터들을 묶어서 클러스터별 특성을 확인해야하는데 특징이 잘 나타나지않을것이다.
![8-3](https://bakey-api.codeit.kr/api/files/resource?root=static&seqId=5810&directory=8-3.png&name=8-3.png)

결국에는 3이 제일 적절할것같다.
그렇다면 최적의 클러스터 개수는 어떻게 찾을 수 있을까?
그를 위해서는 k-means가 잘됐다는 것을 판단할수있는 기준이 필요하다.
### 최적의 k선정 기준
k-means는 k 개의 Centroid에 가까이 모여 있는 데이터들을 하나의 클러스터로 묶어 주는 방법이었죠? 그렇다면, 클러스터마다 속한 데이터와 Centroid 사이 거리의 합이 작아야 잘 된 클러스터링이겠네요.
### 이너시아
그걸 확인하기 위해 사용하는 값이 바로 inertia(이너시아)입니다. inertia는 각 클러스터에 속한 데이터들과 Centroid 사이의 거리를 제곱해서 전부 더한 값입니다.
아래 이미지는 7개의 데이터를 두 개의 클러스터로 나눠 본 예시인데요. 
이렇게 클러스터를 나누면 모든 데이터와 Centroid 사이의 거리가 정해지겠죠? 이 값들을 전부 제곱해서 더한 값이 inertia입니다. 참고로, 아래 예시에서의 Inertia는 43입니다.![8-5](https://bakey-api.codeit.kr/api/files/resource?root=static&seqId=5810&directory=8-5.png&name=8-5.png)
inertia는 `KMeans()`에 데이터로 모델을 학습 시키면 `inertia_`라는 변수에 저장됩니다. 이전 레슨에서 학습시켰던 모델로 한번 확인해 볼게요.


### EIbow Method
그런데, k를 하나로만 정의해서 inertia를 구하면 해당 값이 큰 것인지 작은 것인지 판단하기가 어렵겠죠? 그래서, 서로 다른 k 값 여러 개로 모델을 만든 다음에 각각의 inertia 값을 비교해 봐야 합니다.

그 과정을 진행해 볼게요. 먼저, 기존 실습에서 `scaled_df`에 추가했던 `label` 열을 제거해 줄게요.

K가 하나 말고 여러개를 1~15까지 해서 이너시아 값을 테스트해보겠다.
```python
# scaled_df에 추가했던 label 열을 제거
scaled_df = scaled_df.drop(['label'], axis=1)
# inertia 값 저장할 리스트
inertias = []     

for k in range(1, 16): # k값의 범위 1~15로 지정
    model = KMeans(n_clusters=k, random_state=123)
    model.fit(scaled_df)
    inertias.append(model.inertia_)

# k값에 따른 inertia값 시각화
sns.lineplot(x=range(1, 16), y=inertias, marker='o')

```
이렇게 이너시아를 다 뽑아서 보면![8-6](https://bakey-api.codeit.kr/api/files/resource?root=static&seqId=5810&directory=8-6.2.png&name=8-6.2.png)

이런값이 나오는데 k가 커질수록 이너시아는 반대로 작아진다.
그러면 k가 15일 때가 클러스터링이 가장 잘 된 걸까요? 그렇진 않습니다. inertia는 클러스터의 개수가 늘어날수록 계속 작아집니다. 그러다가, 클러스터가 데이터의 개수만큼 있을 땐 0이 되죠.
근데 클러스터개수가 많아질수록 클러스터링을 하는 의미가 사라진다고 했다.
이너시아가 작다고 무조건 좋은건 아니다.
최적의 클러스터 개수는 inertia가 충분히 작지만, 분석 목적에 부합하도록 적당해야 합니다. 그리고, 보통 그 지점은 시각화 한 그래프의 기울기가 급격하게 줄어드는 구간으로 정의합니다. 예를 들어 위의 그래프를 보면, k 값이 2~3 사이인 구간에서 기울기가 급격하게 줄어들고 있는데요. 따라서 여기서 최적의 k 값은 2나 3이라고 볼 수 있습니다. 이때 그래프의 모양이 마치 팔꿈치 모양 같다고 해서, 이런 식으로 클러스터 개수를 찾는 방법을 Elbow Method라고 부르죠.

급격하게 줄어드는 2,3을 최적으로 볼수있다.
그런데 Elbow Method를 통해 나온 결과를 반드시 따라야 하는 건 아니고요. 
그냥 보조 지표 정도로 활용하고, 상황이나 목적에 맞게 클러스터 개수를 조금 다르게 설정해도 괜찮습니다. 예를 들어 고객들을 좀 더 다양한 세그먼트로 나눠서 보고 싶다면, 클러스터를 2개나 3개 대신 5개로 설정할 수도 있겠죠? 
k 값이 2와 3 사이일 때 이미 기울기가 급격하게 줄어들기는 했지만, 5를 기점으로도 기울기 변화가 거의 없어질 정도로 완만해지고 있다고 볼 수도 있겠네요. 이어지는 레슨에서는 클러스터 개수를 5개로 하여, 클러스터링의 결과를 해석해 보겠습니다.