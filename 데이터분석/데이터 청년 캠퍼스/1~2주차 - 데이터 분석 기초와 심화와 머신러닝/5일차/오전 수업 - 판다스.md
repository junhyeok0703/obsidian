numpy-> 수학적 계산을 위한 라이브러리(배열,선형대수..)
### 결측치 관련 함수들
- dropna : 누락된 데이터가 있는 축을 제외시킨다

- fillna :누락된 데이터를 대신할 값을 채워준다.

- isnull :누락된 값을 알려주는 bool값을 반환해준다.

- notnull: isnull과 반대의 결과를 전달한다.

series와 df의 자료형의 차이점은
**df는 행열로 있는데 series는 list처럼 나열되있는 데이터이다.**
**0이랑 nan값이랑 다름**


#### 2차원 배열로 데이터 프레임 만들기

##### dropna함수의 옵션
 - axis = index , columns를 통해 열을 기준으로 np.nan이 있는 열을 없앨 수 있습니다.
 - how = all(모든 값이 np.nan인 경우만 제거),any(np.nan값이 하나라도 있으면 제거)
 - thresh = 남아있는 값(결측값이 아닌 값)이 몇개여야 행/열을 유지할지
 - subset = 부분집합 |  특정 행/열에 대해서만 dropna를 적용
 - inplace = 원본에 dropna의 결과를 반영할지 여부


- axis
![[Pasted image 20240712093616.png]]
- how
![[Pasted image 20240712100514.png]]
- subset
![[Pasted image 20240712100544.png]]
##### fillna함수의 옵션 - 시계열데이터에 결측값을 채울때이다.
![[Pasted image 20240712100859.png]]

![[Pasted image 20240712101934.png]]
```
원래는 위에 값을 보고 바꿨는데 axios 1로하면 옆왼족오른쪽 값들을 보고 채움

print(f"앞의 값으로 채움{data.fillna(method='ffill',axios=0)}") #기본값임. 행기준으로 보고 바꿈 0
print(f"결측값을 채울건데,최대 몇개씩만 채울것인가: \n {data.fillna(value=0,limit=1)}")
```


#### fillna의  inplace - 원본데이터에 적용
```
# inplace는 원본변수에 적용을 함 0으로 넣는거

data.fillna(value=0,inplace=True)

print(data)
```

### concat 

```
#concat의 옵션

#axis : index(0),columns(1) 어떤 축을 기준으로 데이터프레임을 합칠 것인가

#join : inner(내부 조인) , outer(외부조인))//outer가 기본

#ignore_index : 합치게 되는 데이터프레임의 인덱스를 무시하고, 새 인덱스를 부여
```

```
print(f"행 방향으로 연결: \n {pd.concat([df1,df2],axis=0)}")
```
```
print(f"열 방향으로 연결: \n {pd.concat([df1,df2],axis=1)}")
```


#### concat - join

```
#외부조인 그냥 막붙임 맞는게 없어도 (열이름이 맞는게 없어도그냥붙임)

# 외부조인(기본값),따로 지정해주지않으면 외부조인으로 붙는다

# 외부조인은 행,열 방향에 따라 concat을 하지만

# 두데이터프레임사이에 공통점이 없더라도 빈부분은 nan으로 두고 데이터프레임을 합쳐준다.

  

print(f"외부 조인 \n {pd.concat([df1,df3])}")
```

```
#내부조인 (외부조인은 기본값임) 맞는게 있어야지 붙여준다

# 외부 조인이 공통점이 없더라도 합쳐주지만

# 내부조인은 열이름이나 , 인덱스가 동일해야하만 concat을 수행할수있다.

print(f"내부 조인 \n {pd.concat([df1,df3],axis=1,join='inner')}")
```




#### concat - ignore_index
```
print(f"ignore_index를 쓰지 않으면 : \n {pd.concat([df1,df2])}")
```

```
print(f"ignore_index를 쓸때 : \n {pd.concat([df1,df2],ignore_index=True)}")
```