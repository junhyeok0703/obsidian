

LLM을 많은 파라미터를 가지고있어서 파인튜닝하기 쉽지않다.
컴퓨팅리소스가 쎄지않을경우 도와주는 라이브러리가  허깅페이스에서 공개한 PEFT임 
모든걸 다시 학습시키는게 아니라 사전훈련언어모델에서 일부만 다시 학습시키는거임 (매개변수만 미세조정하여 저장비용을 크게 줄임)

### PEFT 모델
![[스크린샷 2024-03-29 23.32.20.png]]
이렇게 허깅페이스가 제공함 


### LoRA
프리트레이닝웨이트를 재학습하는것이 원래 파인튜닝 컨셉인데 추가적으로 오토엔코더같은 로우랭크로 축소하고 다시 풀어내는 행렬 A,B파라미터를 만든 다음에 이걸학습시키는 형태로 문제를 치환했고 다시 복구할때는 A,B,X더한걸로 처리하게 됨


https://colab.research.google.com/drive/1ViGQuvsBhAbzcXvOyNawlWwux-VXMx1L?usp=sharing
로라로 파인튜닝해보기


여러가지의 파인튜닝 기법과 라이브러리를 쓸수있다. -> 대충 완전히 파라미터를 다시 학습하는게 아니라 파라미터일부만 떼서 넣어가지고 파인튜닝하게 됨 거의 그래서 대규모 컴퓨터 리소스가 필요없이 학습이 가능하게 된다.