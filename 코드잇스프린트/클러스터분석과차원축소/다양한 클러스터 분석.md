### 계층적 클러스터링
계층적클러스터링 -> k값 안정하고 일단 클러스터링하고 거기서 필요한 k로 짤라서 쓰는거임 (덴드로그램 계층tree)

바텀업.
1. 가장 가까운 데이터 쌍을 묶기
2. 묶인 데이터끼리도 거리계산
3. 클러스터링 반복
ward거리 (이너시아의 증가분) 
이너시아의 증가한 변화량
이너시아가 작으면 작을수록 옹기종기 모여있는 클러스터라고 했는데
옹기종기부터 만들고 옹기종기로 또 묶겠다

묶이는 기준 : 와드거리의 기준으로 최소가 되는거(처음은 그냥 데이터각각이 클러스터로 침)

1. 각 데이터가 클러스터
		- 처음에는 각 데이터가 자신의 중심을 가지는 개별 클러스터로 시작
2. 두 클러스터 묶기
	- 두 점 A와 B를 하나의 클러스터로 묶으면 , 새로운 중심은 두점의 중간지점이 됨
3. 거리 계산
	- 새로운 중심과 A,B간의 거리 제곱합을 구하고 , 이전 거리와의 차이(증가분)을 계산
	- 증가분은 이전과의 비교 개념이 포함
4. ward거리
	- 
### 핵심코드(scipy에 있음 얘는)

```python
from scipy.cluster.hierarchy import dendrogram , linkage, cnt_tree
import matplotlib.pyplot as plt
import pandas as pd

# 계층적 클러스터링 학습 (ward 거리 사용)

model = linkage(scaled_df,'ward')

# 덴드로그램 시각화

plt.figure(figsize=(12, 6))

dendrogram(model,labels=scaled_df.index)
# 이렇게 ward거리로 클러스터링하고 덴드로그램 시각화


# cuttree로 자르기 
```

### 밀도기반 클러스터링(DBSCAN)
기하학적인 형태의 데이터를 클러스터링
유사한데이터가 바로 옆에 있다. (옆에있는걸 묶는다계속)
k-means는 중심으로부터의 거리가 가깝다고 모든 데이터 한명이 기준이 되어야되고 그걸 계속 묶는것임


### GMM (분포기반클러스터링)
타원형 -> 정규분포를 묶는다
정규분포니까 어떤값이 어디 위치에 있는지 확률을 구할수있음
