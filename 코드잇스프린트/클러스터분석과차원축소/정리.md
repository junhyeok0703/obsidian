### 첫번째 상관관계와 선형회귀분석
상관관계
추세선을 그리고 이 경향을 보는게 -1 ~ 1 을 보게 되면 상관관계를 볼수있다.

추세선의 기울기 = 회귀 계수
추세선 = 회귀선
회귀 계수에 대한 가설검정을 하는것이 회귀분석
회귀 분석의 결과표가 나오게 됨 -> 결과표에는 p값 < 0.05보다 작은거면 통계적으로 유의미
귀무가설 기각 -> 대립가설 채택
회귀계수가 0이 아니다! 를 채택 | 기울기가 0이 아니다.  두변수사이에 선형관계가 있다. 이게
선형회귀분석


### 두번째 클러스터분석 , k-means , elbow method, 
레이블이 없어도 됨 -> 비지도 학습

데이터를 묶는 것 

데이터를 묶는 것의 기준이 필요함 -> 맘대로 묶으면 안됨

기준을 잡기 위해 가장많이쓰는방법 -> K-means

K-means는 기준이 거리이다.

뭐와 뭐 사이의 거리일까?
중심과 각각 데이터 사이의 거리가 가까운거
가까운거가 중심주변으로 묶임

묶인데이터의 평균을 내서 다시 중심점옮겨서 또 평균을 내주고 이런식으로
중심의 위치를 찾게 된다.
K=중심의 개수
means은 거리의 평균
K를 잘못설정하면 아예 안묶일수도있다.
K를 정하는 방법이 elbow method가 있다.

elbow method는 팔꿈치 모양인 k증가함에 따라 이너시아 그래프이다.

이너시아 : 중심과 각데이터의 거리제곱의 합이다. (이게 작으면 좋은이유가 중심과의 거리가 작은거니까)

k가 크면클수록 이너시아가 작아진다. 분산이 되니까

기울기가 가장 가파른 / k를 늘림에 따라 -> 그게 베스트k이다


### k-means 결과해석
1. 각 라벨별로 그룹을 나눠서 count해서 보기
2. 각 라벨별로 scatterplot찍기 
3. 중심점도 찍어보기 (표준화되면 이값은 못씀 단위가 달라져서) -> 그래서 원본값에다 레이블을 넣고 group.mean하면됨


### 차원의 저주
차원이 커지면 모델성능이 떨어진다.
차원의 저주는 데이터 밀도가 낮아지면서 발생하는 당연한 문제이다.
영역을 학습하기위해 학습데이터가 없어져서 그렇다


차원의 저주 해결방법 
1. 첫번째는 데이터 수를 늘린다.
2. 차원을 축소한다
3. 모델을 단순한거 쓴다.


### 중심점도 잘골라야함 init='k-means++' -> 안정적은 클러스터링을 위해
2개의 중심점을 고른다고 할때 두개의 중심점은 최대한 멀리떨어져있고 이 각각의 중심점은 데이터와 최대한 가깝게 (그냥 데이터 위치중 하나 뽑으면 됨)

### label을 뽑는 2가지의 방법
model.labels_ , model.predict(df)
### 중심점 찍기
model.cluster_centers_ <- 표준화된 데이터로 하게 되면 이건 원래 값이 아니다. 
표준화된 데이터말고 원본데이터에 레이블을 넣고 label로 groupby를 해서 mean하면 그게 중심이 됨
![[Pasted image 20241205183309.png]]
