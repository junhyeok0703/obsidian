
## 프로젝트의 목적
 - 특정 좁은 분야의 지식에 있어서 현존 최강의 LLM보다 강령학 Fine-Tuning 된 LLM을 만들어보자 ! 

### 전이학습
-> 전이학습 == 파인튜닝 이미 학습된 Neural Networks의 파라미터를 새로운 Task에 맞게 다시 미세조정하는 것이다.

적은 리소스 , 적은 컴퓨팅으로 가능! 

### KorQuad데이터셋이란? 
![[스크린샷 2024-03-30 00.58.30.png]] 
이런 데이터셋임 -> gpt4도 대답 잘 못해줌

특정한 좁은 분야의 지식에서는 챗지피티도 모름 우리가 원하는 딱 좁은 도메인에 대해서는 파인튜닝된 LLM이 Gpt보다 강력하게 세팅가능성을 확인할수있음. 

### KorQuad데이터셋 소개
SQuAD
![[스크린샷 2024-03-30 01.02.54.png]]
스탠포드에서 질문과 답으로 구성된 데이터셋임 

지문 , 질문 , 답변으로 구성됨![[스크린샷 2024-03-30 01.03.58.png]]
KorQuad
한국어 버전임 그냥![[스크린샷 2024-03-30 01.05.42.png]]
answer_start -> 정답위치임

### 데이터 정제하기
https://colab.research.google.com/drive/1AwFa1pIlfZqbDxDkIjyFPuUXtI5LGNzq?usp=sharing

과정 설명 : 
1. 데이터 다운로드
2. 한개의 지문과 5개정도의 질문과답이 있음 
3. 그것을 질문과 답으로 이뤄져있는 딕셔너리로 세팅 
4. 프롬프트로 다 만들어주기 
5. Response를 비워두고 퀘스첸만 프롬프트로 작성할경우 정답이 잘나오면 학습이 잘된거임 
6. 키가 text로 들어가있고 value를 우리가 프롬프트로 만들어준 문장을 넣어줘야지 라이브러리가 잘 작동함
7. 이 json에 허깅페이스에 제공되는 파인튜닝 라이브러에 넣어줄거임
8. 그전에 잠깐 성능이 문제가 있을것같아서 Data Augmentation하기 위해 (비슷한 문장이 들어갔는데 정답이 안나올수있음) -> chatgpt로 비슷한 문장 만들어 제낌
![[스크린샷 2024-03-30 01.17.58.png]]
데이터를 한번더 정제해서 20X 10하여서 200개를 넣음

9. 다시 또 정제 2번 거쳐서 프롬프트 json으로 바꿔넣기까지 autotrain-advanced라이브러리를 사용할거임


## ---------------데이터 정제끝

### 데이터 학습 ![[스크린샷 2024-03-30 01.22.03.png]]

https://colab.research.google.com/drive/1yf1MToiMQVq32nxL6-PRMq_qS7Az8dYM?usp=sharing

### 진행순서 
1. gpu연결확인
2. 허깅페이스 / autotrain-advanced 라이브러리사용
3. 복잡한 코드를 작성하지않고 커멘드로 가능
4. 라이브러리설치 -> 파이토치업데이트
5. 오토트레인모듈로 LLM은 간단하게 학습가능 
6. project_name -> 그냥 폴더명
7. 어그멘티드데이터는 주석처리안한거 전 데이터는 주석처리한거
8. model은 프리트레이닝 모델을 뭐쓸거냐 라마2프리트레이닝가져온거임(허깅페이스에 올라온 모델임)
9. data-path은 그냥 데이터경로(정제해둔 폴더에 json파일 넣어줘야함)
10. 그 text로 아까해둔이유가 그거임 
11. 중요한점 model_max_length는 우리 학습데이터의 길이임 4096까지 가능

이렇게 설정해서 모델을 학습이 된거임 ㅋ




### 모델성능측정

https://colab.research.google.com/drive/1HJ-PX3BVteiUaVVFlVzNIrp8Zj_UB6sZ?usp=sharing


